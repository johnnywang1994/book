import{_ as o,r as t,o as l,c as d,a as n,d as e,e as a,f as s}from"./app-6147e6e2.js";const c={},h=e("h1",{id:"在電腦裡搞一個-rwkv-ai-小助手",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#在電腦裡搞一個-rwkv-ai-小助手","aria-hidden":"true"},"#"),a(" 在電腦裡搞一個 RWKV AI 小助手")],-1),p=e("p",null,"Hi 大家好，我是 Johnny。最近有感於 AI 技術不斷蓬勃發展，想說來研究一下時下最新的 AI 技術資訊，當然最知名的除了為人所熟知的微軟 OpenAI ChatGPT之外，大概就是 Facebook Meta 的 Llama 了吧",-1),u=e("p",null,"但上述兩個都已經被各位大佬講到爛掉了，沒有小弟我的發言權Q_Q，今天這篇要來以一位 AI 菜鳥的角度，學習、介紹一款相對比較沒有被大家討論的技術叫做「RWKV」（Receptance Weighted Key Value）",-1),b=e("h2",{id:"介紹",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#介紹","aria-hidden":"true"},"#"),a(" 介紹")],-1),_=e("p",null,"開始之前，先來看個官方自我介紹",-1),v=e("blockquote",null,[e("p",null,"RWKV 是一種具有 Transformer 級 LLM 性能的 RNN。它可以像 GPT（可並行化）一樣直接訓練。因此，它結合了 RNN 和 Transformer 的優點 - 出色的性能、快速推理、節省 VRAM、快速訓練、「無限」ctx_len 和免費句子嵌入。")],-1),m=e("p",null,"是由 Peng Bo 受 AFT（Attention-Free Transformer）等語言模型啟發，設計並進一步開發的大型語言模型（Large Language Model）",-1),g=e("h2",{id:"設計架構",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#設計架構","aria-hidden":"true"},"#"),a(" 設計架構")],-1),k={href:"https://rwkv-wiki.github.io/",target:"_blank",rel:"noopener noreferrer"},w={href:"https://github.com/BlinkDL/ChatRWKV/blob/main/RWKV_in_150_lines.py",target:"_blank",rel:"noopener noreferrer"},f=s('<p>最終針對 token 的計算，計算複雜度從 O(n^2) 壓縮到 O(n)，也因此更節省 VRAM 且快速</p><p><img src="https://rwkv-wiki.github.io/img/GPT_versus_RWKV.svg" alt=""></p><h2 id="實際下載玩玩" tabindex="-1"><a class="header-anchor" href="#實際下載玩玩" aria-hidden="true">#</a> 實際下載玩玩</h2><p>相信有在本機環境中，實際跑過 Llama model 的人一定都知道，其對於中文語意的理解能力實在不敢恭維，必須另外安裝中文訓練的擴充才能更好地以中文回答問題，且本機跑的速度非常緩慢，常常跑一跑就整個卡住</p><p>那使用 RWKV 呢？</p><h3 id="下載" tabindex="-1"><a class="header-anchor" href="#下載" aria-hidden="true">#</a> 下載</h3>',6),V={href:"https://github.com/RWKV/rwkv.cpp",target:"_blank",rel:"noopener noreferrer"},x=s(`<div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ <span class="token function">git</span> clone https://github.com/RWKV/rwkv.cpp
$ <span class="token builtin class-name">cd</span> rwkv.cpp
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="安裝" tabindex="-1"><a class="header-anchor" href="#安裝" aria-hidden="true">#</a> 安裝</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ brew <span class="token function">install</span> cmake
$ cmake <span class="token builtin class-name">.</span>
$ cmake <span class="token parameter variable">--build</span> <span class="token builtin class-name">.</span> <span class="token parameter variable">--config</span> Release
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>完成後會看到 <code>librwkv.dylib</code> 在資料夾中</p><h3 id="取得-rwkv-model" tabindex="-1"><a class="header-anchor" href="#取得-rwkv-model" aria-hidden="true">#</a> 取得 RWKV model</h3>`,5),R={href:"https://huggingface.co/BlinkDL/rwkv-4-pile-1b5/blob/main/RWKV-4-Pile-1B5-20220929-ctx4096.pth",target:"_blank",rel:"noopener noreferrer"},W=s(`<h3 id="轉換為-rwkv-cpp-格式" tabindex="-1"><a class="header-anchor" href="#轉換為-rwkv-cpp-格式" aria-hidden="true">#</a> 轉換為 rwkv.cpp 格式</h3><p>轉換之前，先安裝 python 的依賴</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ pip <span class="token function">install</span> torch numpy tokenizer
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>轉換成 ggml - FP16</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ python python/convert_pytorch_to_ggml.py ~/Downloads/RWKV-4-Pile-1B5-20220929-ctx4096.pth ~/Downloads/rwkv.cpp-4pile-1b5.bin FP16
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>quantize 成 Q5_1 或是其他你想要的格式（差別在解析準確度跟速度）</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ python python/quantize.py ~/Downloads/rwkv.cpp-4pile-1b5.bin ~/Downloads/rwkv.cpp-4pile-1b5-Q5_1.bin Q5_1
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="執行-chat-with-bot" tabindex="-1"><a class="header-anchor" href="#執行-chat-with-bot" aria-hidden="true">#</a> 執行 Chat with BOT</h3><p>接下來就是見證奇蹟的時刻！！輸入下面指令，啟動指定的 model 後，就可以在 Terminal 中與它交談了</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ python python/chat_with_bot.py ~/Downloads/rwkv.cpp-4pile-1b5-Q5_1.bin
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><blockquote><p>個人在本機實測，MacOS M1 VRAM 16G 跑 3B 的 model 還蠻順暢的，但 7B 的就會卡頓，使用時要特別注意，不要害電腦 CPU 燒掉就尷尬了</p></blockquote>`,11),y=e("h2",{id:"結論",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#結論","aria-hidden":"true"},"#"),a(" 結論")],-1),K=e("p",null,[a("實際下載玩一次之後，發現比 Llama 還容易上手，而且對於中文的理解能力更準確，即使是 1B5 的 model 也還是具有一定的應答能力，相比於同規格的 Llama model，反應力與回答準確率是高出不少，個人蠻期待這個技術後續的發展，我自己還動手把他的 "),e("code",null,"chat_with_bot.py"),a(" 改寫成了 API，拿來做成一些小服務，變成我的玩具迷你 ai 助手了 XDDD")],-1),B=e("p",null,"今天就分享到這拉，希望大家會喜歡，我們下篇文章見～=V=",-1),L=e("h2",{id:"參考",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#參考","aria-hidden":"true"},"#"),a(" 參考")],-1),A={href:"https://github.com/RWKV/rwkv.cpp",target:"_blank",rel:"noopener noreferrer"},T={href:"https://rwkv-wiki.github.io/",target:"_blank",rel:"noopener noreferrer"},D={href:"https://johanwind.github.io/2023/03/23/rwkv_details.html",target:"_blank",rel:"noopener noreferrer"};function P(M,I){const r=t("SocialBlock"),i=t("ExternalLinkIcon");return l(),d("div",null,[h,n(r,{hashtags:"ai,rwkv,python,chatgpt"}),p,u,b,_,v,m,g,e("p",null,[a("本質上來說，RWKV 跟 GPT 完全不一樣，R-Transformer 是針對高維嵌入導致位置編碼失效的一種解決方案，而 RWKV 則使用 WKV 計算取代 Self-Attension 的部分進行優化，詳細說明可"),e("a",k,[a("參考這篇"),n(i)]),a("，實作可以看這邊"),e("a",w,[a("RWKV_in_150_lines.py"),n(i)])]),f,e("p",null,[a("筆者以 MacOS M1 環境示範，不同環境的安裝教學請參考"),e("a",V,[a("官方文件"),n(i)])]),x,e("p",null,[a("可以去 Hugging Face 下載，這裡提供一個簡單的範例 "),e("a",R,[a("BlinkDL/rwkv-4-pile-1b5"),n(i)])]),W,n(r,{hashtags:"ai,rwkv,python,chatgpt"}),y,K,B,L,e("ul",null,[e("li",null,[e("a",A,[a("github/rwkv.cpp"),n(i)])]),e("li",null,[e("a",T,[a("RWKV Wiki"),n(i)])]),e("li",null,[e("a",D,[a("How the RWKV language model works"),n(i)])])])])}const N=o(c,[["render",P],["__file","rwkv-intro.html.vue"]]);export{N as default};
