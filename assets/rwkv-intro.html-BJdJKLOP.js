import{_ as i,c as t,b as a,a as s,d as r,r as l,o}from"./app-DxoW7puS.js";const p={};function c(h,e){const n=l("SocialBlock");return o(),t("div",null,[e[0]||(e[0]=a("h1",{id:"在電腦裡搞一個-rwkv-ai-小助手",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#在電腦裡搞一個-rwkv-ai-小助手"},[a("span",null,"在電腦裡搞一個 RWKV AI 小助手")])],-1)),s(n,{hashtags:"ai,rwkv,python,chatgpt"}),e[1]||(e[1]=r(`<p>Hi 大家好，我是 Johnny。最近有感於 AI 技術不斷蓬勃發展，想說來研究一下時下最新的 AI 技術資訊，當然最知名的除了為人所熟知的微軟 OpenAI ChatGPT之外，大概就是 Facebook Meta 的 Llama 了吧</p><p>但上述兩個都已經被各位大佬講到爛掉了，沒有小弟我的發言權Q_Q，今天這篇要來以一位 AI 菜鳥的角度，學習、介紹一款相對比較沒有被大家討論的技術叫做「RWKV」（Receptance Weighted Key Value）</p><h2 id="什麼是-rwkv-receptance-weighted-key-value" tabindex="-1"><a class="header-anchor" href="#什麼是-rwkv-receptance-weighted-key-value"><span>什麼是 RWKV?(Receptance Weighted Key Value)</span></a></h2><p>是由 Peng Bo 受 AFT（Attention-Free Transformer）等語言模型啟發，設計並進一步開發的大型語言模型（Large Language Model）</p><ul><li>RWKV 是一種具有 Transformer 級 LLM 性能的 RNN。</li><li>可以像 GPT（可並行化）一樣直接訓練。結合了 RNN 和 Transformer 的優點，同時解決傳統 RNN 的缺陷（梯度消失、爆炸）</li><li>出色的性能、快速推理、節省 VRAM、快速訓練、「無限」ctx_len 和免費句子嵌入。</li></ul><blockquote><p>AFT 是 Apple 公司提出的一種新型的神經網路模型，減少 transformer 的計算量、提升性能</p></blockquote><h2 id="設計架構" tabindex="-1"><a class="header-anchor" href="#設計架構"><span>設計架構</span></a></h2><p>本質上來說，RWKV 跟 GPT 完全不一樣，R-Transformer 是針對高維嵌入導致位置編碼失效的一種解決方案，而 RWKV 則改造 AFT，採用 Linear Transformer 算法，使用 WKV 計算取代 Self-Attension 的部分進行優化，詳細說明可<a href="https://rwkv-wiki.github.io/" target="_blank" rel="noopener noreferrer">參考這篇</a>，實作可以看這邊<a href="https://github.com/BlinkDL/ChatRWKV/blob/main/RWKV_in_150_lines.py" target="_blank" rel="noopener noreferrer">RWKV_in_150_lines.py</a></p><p>最終針對 token 的計算，在不考慮 embedding 維度的情況下，計算複雜度從 O(n^2) 壓縮到 O(n)，也因此更節省 VRAM 且快速</p><blockquote><p>Transformer 核心是 self-attention 機制，整句並行化處理，訓練效率高、計算複雜度高，但會有 Position Embedding 問題（詞序遺失）</p></blockquote><blockquote><p>R-Transformer 則是透過單個 RNN 捕捉位置來代替 Position Embedding，解決傳統 RNN 問題的同時也能並行化處理，但同樣計算複雜度高</p></blockquote><p><img src="https://pic1.zhimg.com/80/v2-78be23cd2bea7e43e21fccb7df60929c_720w.webp" alt="self-attention 示意圖"></p><p><img src="https://rwkv-wiki.github.io/img/GPT_versus_RWKV.svg" alt="GPT vs RWKV 架構示意圖"></p><p><img src="https://github.com/BlinkDL/ChatRWKV/raw/main/RWKV-v5-benchmark-1.png" alt=""></p><h2 id="性能對比" tabindex="-1"><a class="header-anchor" href="#性能對比"><span>性能對比</span></a></h2><p>RWKV 模型，時間消耗隨序列長度呈現線性增加，時間消耗遠小於其他各種 Transformer</p><p><img src="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3670048-19d2-4da6-94f4-0866a5a38640_616x463.png" alt="rwkv cumulative time compare to others"></p><h2 id="實際下載玩玩" tabindex="-1"><a class="header-anchor" href="#實際下載玩玩"><span>實際下載玩玩</span></a></h2><p>相信有在本機環境中，實際跑過 Llama model 的人一定都知道，其對於中文語意的理解能力實在不敢恭維，必須另外安裝中文訓練的擴充才能更好地以中文回答問題，且本機跑的速度非常緩慢，常常跑一跑就整個卡住</p><p>那使用 RWKV 呢？</p><h3 id="下載" tabindex="-1"><a class="header-anchor" href="#下載"><span>下載</span></a></h3><p>筆者以 MacOS M1 環境示範，不同環境的安裝教學請參考<a href="https://github.com/RWKV/rwkv.cpp" target="_blank" rel="noopener noreferrer">官方文件</a></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">$ <span class="token function">git</span> clone https://github.com/RWKV/rwkv.cpp</span>
<span class="line">$ <span class="token builtin class-name">cd</span> rwkv.cpp</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="安裝" tabindex="-1"><a class="header-anchor" href="#安裝"><span>安裝</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">$ brew <span class="token function">install</span> cmake</span>
<span class="line">$ cmake <span class="token builtin class-name">.</span></span>
<span class="line">$ cmake <span class="token parameter variable">--build</span> <span class="token builtin class-name">.</span> <span class="token parameter variable">--config</span> Release</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>Mac M1 晶片執行完 <code>cmake .</code> 後需注意 <code>CMAKE_SYSTEM_PROCESSOR: arm64</code>，如果偵測結果是 <code>x86_64</code>，需要手動在 <code>CMakeLists.txt</code> 檔案裡，找到 <code># Compile flags</code>，並加入 <code>set(CMAKE_SYSTEM_PROCESSOR &quot;arm64&quot;)</code></p></blockquote><p>完成後會看到 <code>librwkv.so</code> (Linux) 或 <code>librwkv.dylib</code> (MacOS) 在資料夾中</p><h3 id="取得-rwkv-model" tabindex="-1"><a class="header-anchor" href="#取得-rwkv-model"><span>取得 RWKV model</span></a></h3><p>可以去 Hugging Face 下載，這裡提供一個簡單的範例 <a href="https://huggingface.co/BlinkDL/rwkv-4-pile-1b5/blob/main/RWKV-4-Pile-1B5-20220929-ctx4096.pth" target="_blank" rel="noopener noreferrer">BlinkDL/rwkv-4-pile-1b5</a></p><h3 id="轉換為-rwkv-cpp-格式" tabindex="-1"><a class="header-anchor" href="#轉換為-rwkv-cpp-格式"><span>轉換為 rwkv.cpp 格式</span></a></h3><p>轉換之前，先安裝 python 的依賴（以下都是使用 python3）</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">$ pip <span class="token function">install</span> torch numpy tokenizer</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>轉換成 ggml - FP16</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">$ python python/convert_pytorch_to_ggml.py ~/Downloads/RWKV-4-Pile-1B5-20220929-ctx4096.pth ~/Downloads/rwkv.cpp-4pile-1b5.bin FP16</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>quantize 成 Q5_1 或是其他你想要的格式（差別在解析準確度跟速度）</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">$ python python/quantize.py ~/Downloads/rwkv.cpp-4pile-1b5.bin ~/Downloads/rwkv.cpp-4pile-1b5-Q5_1.bin Q5_1</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="執行-chat-with-bot" tabindex="-1"><a class="header-anchor" href="#執行-chat-with-bot"><span>執行 Chat with BOT</span></a></h3><p>接下來就是見證奇蹟的時刻！！輸入下面指令，啟動指定的 model 後，就可以在 Terminal 中與它交談了</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">$ python python/chat_with_bot.py ~/Downloads/rwkv.cpp-4pile-1b5-Q5_1.bin</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><blockquote><p>個人在本機實測，MacOS M1 VRAM 16G 跑 3B 的 model 還蠻順暢的，但 7B 的就會卡頓，使用時要特別注意，不要害電腦 CPU 燒掉就尷尬了</p></blockquote>`,40)),s(n,{hashtags:"ai,rwkv,python,chatgpt"}),e[2]||(e[2]=r('<h2 id="結論" tabindex="-1"><a class="header-anchor" href="#結論"><span>結論</span></a></h2><p>實際下載玩一次之後，發現比 Llama 還容易上手，而且對於中文的理解能力更準確，即使是 1B5 的 model 也還是具有一定的應答能力，相比於同規格的 Llama model，反應力與回答準確率是高出不少，個人蠻期待這個技術後續的發展，我自己還動手把他的 <code>chat_with_bot.py</code> 改寫成了 API，拿來做成一些小服務，變成我的玩具迷你 ai 助手了 XDDD</p><p>雖然 RWKV 模型號稱地表上「最環保的模型」，但畢竟生態系、算法加速 library 生態規模與 Transformer 差距非常大，未來能不能發展成主流還要需要再觀察</p><p>今天就分享到這拉，希望大家會喜歡，我們下篇文章見～=V=</p><h2 id="參考" tabindex="-1"><a class="header-anchor" href="#參考"><span>參考</span></a></h2><ul><li><a href="https://github.com/RWKV/rwkv.cpp" target="_blank" rel="noopener noreferrer">github/rwkv.cpp</a></li><li><a href="https://github.com/BlinkDL/ChatRWKV" target="_blank" rel="noopener noreferrer">ChatRWKV</a></li><li><a href="https://rwkv-wiki.github.io/" target="_blank" rel="noopener noreferrer">RWKV Wiki</a></li><li><a href="https://johanwind.github.io/2023/03/23/rwkv_details.html" target="_blank" rel="noopener noreferrer">How the RWKV language model works</a></li><li><a href="https://www.cnblogs.com/skytier/p/17705011.html" target="_blank" rel="noopener noreferrer">RWKV 解讀-Transformer 時代的新 RNN</a></li><li><a href="https://zhuanlan.zhihu.com/p/377777462" target="_blank" rel="noopener noreferrer">R-Transformer用 RNN 代替位置編碼</a></li></ul>',6))])}const m=i(p,[["render",c]]),b=JSON.parse('{"path":"/articles/js/rwkv-intro.html","title":"在電腦裡搞一個 RWKV AI 小助手","lang":"zh-TW","frontmatter":{},"git":{"updatedTime":1748788505000,"contributors":[{"name":"johnnywang","username":"johnnywang","email":"johnnywang@test.com","commits":2,"url":"https://github.com/johnnywang"},{"name":"Lindy Liao","username":"","email":"meiliao1207@gmail.com","commits":1}],"changelog":[{"hash":"f01bfa128b4d33fbeddb8abb1697b5391b273d28","time":1748788505000,"email":"meiliao1207@gmail.com","author":"Lindy Liao","message":"UPD"},{"hash":"19ca78bf291fca56fe7e392524923775549f779c","time":1710772220000,"email":"johnnywang@test.com","author":"johnnywang","message":"✨ UPD"},{"hash":"f92393f9ba7d841d0d48179594ea2762414bcce1","time":1709031931000,"email":"johnnywang@test.com","author":"johnnywang","message":"✨ add rwkv-intro"}]},"filePathRelative":"articles/js/rwkv-intro.md"}');export{m as comp,b as data};
